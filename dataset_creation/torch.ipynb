{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class ERA5_With_Observations(Dataset):\n",
    "    def __init__(self, csv_file, label_columns, date_column, lat_column, lon_column, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with data.\n",
    "            label_columns (list of strings): List of column names for the labels/targets.\n",
    "            date_column (string): The column name for the date.\n",
    "            lat_column (string): The column name for latitude.\n",
    "            lon_column (string): The column name for longitude.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.label_columns = label_columns  # Multiple label columns\n",
    "        self.date_column = date_column\n",
    "        self.lat_column = lat_column\n",
    "        self.lon_column = lon_column\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Convert the date column to datetime and then to a timestamp (e.g., seconds since epoch)\n",
    "        self.data[self.date_column] = pd.to_datetime(self.data[self.date_column], errors='coerce')\n",
    "        self.data['date_timestamp'] = self.data[self.date_column].astype(int) / 10**9  # Convert to seconds since epoch\n",
    "        \n",
    "        # Group data by date and merge latitudes and longitudes as arrays\n",
    "        self.date_groups = self.data.groupby('date_timestamp').agg({\n",
    "            'latitude': list,\n",
    "            'longitude': list,\n",
    "            **{label: list for label in self.label_columns}  # Keep all label values as arrays\n",
    "        }).reset_index()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.date_groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Extract the grouped row by index\n",
    "        row = self.date_groups.iloc[idx]\n",
    "        \n",
    "        # Extract the date, latitude and longitude arrays, and labels arrays\n",
    "        date = row['date_timestamp']\n",
    "        latitude = np.array(row['latitude'])\n",
    "        longitude = np.array(row['longitude'])\n",
    "        \n",
    "        # Convert lat/long arrays to a 2D array (if desired)\n",
    "        location = np.column_stack((latitude, longitude))\n",
    "        \n",
    "        # Extract label arrays\n",
    "        labels = {label: torch.tensor(row[label], dtype=torch.float32) for label in self.label_columns}\n",
    "        \n",
    "        # Combine into a sample dictionary\n",
    "        sample = {\n",
    "            'date': torch.tensor(date, dtype=torch.float32),\n",
    "            'location': torch.tensor(location, dtype=torch.float32),  # Array of lat/long pairs\n",
    "            'labels': labels  # Labels as arrays\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "def coarsen_data(df, coarsen_factor=2):\n",
    "    \"\"\"\n",
    "    Coarsen the DataFrame's latitude and longitude into bins of the specified coarsen factor.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing 'longitude', 'latitude' columns.\n",
    "    - coarsen_factor: int, the factor by which to coarsen the grid (default is 5 for 5째x5째 bins).\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with binned latitude and longitude.\n",
    "    \"\"\"\n",
    "    # Define bins for latitude and longitude\n",
    "    long_bins = np.arange(-20, 55, coarsen_factor)\n",
    "    lat_bins = np.arange(-40, 40, coarsen_factor)\n",
    "    \n",
    "    # Bin the latitude and longitude columns\n",
    "    df['longitude_bin'] = pd.cut(df['longitude'], bins=long_bins, include_lowest=True)\n",
    "    df['latitude_bin'] = pd.cut(df['latitude'], bins=lat_bins, include_lowest=True)\n",
    "    \n",
    "    return df, long_bins, lat_bins\n",
    "\n",
    "def plot_1_variable_from_item(item, variable):\n",
    "    \"\"\"\n",
    "    Plot a specific timestep from an item of the Dataset, with latitude and longitude representing top-right corners of 5째x5째 grid cells.\n",
    "    \n",
    "    Parameters:\n",
    "    - item: A dictionary containing 'date', 'latitude', 'longitude', and the variable to plot.\n",
    "    - variable: str, the variable name to plot.\n",
    "    \"\"\"\n",
    "    # Coarsen the data\n",
    "    latitude = item['location'][:, 0]  # Latitudes\n",
    "    longitude = item['location'][:, 1]  # Longitudes\n",
    "\n",
    "    # Create a DataFrame with latitude, longitude, and variable data\n",
    "    data = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        variable: item['labels'][variable]  # Assuming item['labels'] is a dict with variables\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Coarsen the data\n",
    "    df, long_bins, lat_bins = coarsen_data(df)\n",
    "    \n",
    "    # Extract the date from the item\n",
    "    time = pd.to_datetime(item['date'], unit='s')  # Convert to datetime (if it's a timestamp)\n",
    "    \n",
    "    # Filter DataFrame for the specified time (though there's only one row here)\n",
    "    df_filtered = df\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        print(f\"No data available for {time}.\")\n",
    "        return\n",
    "\n",
    "    # Pivot table to create a grid for plotting\n",
    "    grid = df_filtered.pivot_table(\n",
    "        index='latitude_bin', columns='longitude_bin', values=variable, fill_value=np.nan\n",
    "    )\n",
    "\n",
    "    # Extract the bin boundaries from the intervals\n",
    "    lon_bins = [interval.mid for interval in grid.columns]\n",
    "    lat_bins = [interval.mid for interval in grid.index]\n",
    "    values_grid = grid.values\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 10), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "    ax.coastlines(resolution=\"10m\")\n",
    "\n",
    "    # Create meshgrid for plotting\n",
    "    lon_grid, lat_grid = np.meshgrid(lon_bins, lat_bins)\n",
    "\n",
    "    mesh = ax.pcolormesh(\n",
    "        lon_grid, lat_grid, values_grid,\n",
    "        cmap=plt.cm.coolwarm, transform=ccrs.PlateCarree(), shading='auto'\n",
    "    )\n",
    "    \n",
    "    ax.set_extent([-20, 55, -40, 40], crs=ccrs.PlateCarree())\n",
    "\n",
    "    plt.colorbar(mesh, ax=ax, shrink=0.6, label=variable)\n",
    "    formatted_time = time.strftime(\"%B %d, %Y at %I:%M %p\")\n",
    "    plt.title(f\"ERA5 - Africa {variable} on {formatted_time}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m\n\u001b[1;32m     12\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ERA5_With_Observations(csv_file\u001b[38;5;241m=\u001b[39mcsv_file, \n\u001b[1;32m     13\u001b[0m                                 label_columns\u001b[38;5;241m=\u001b[39mlabel_columns, \n\u001b[1;32m     14\u001b[0m                                 date_column\u001b[38;5;241m=\u001b[39mdate_column,\n\u001b[1;32m     15\u001b[0m                                 lat_column\u001b[38;5;241m=\u001b[39mlat_column,\n\u001b[1;32m     16\u001b[0m                                 lon_column\u001b[38;5;241m=\u001b[39mlon_column)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create DataLoader\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define file path and columns\n",
    "csv_file = 'dataset.csv'  # Replace with your file path\n",
    "label_columns = ['not_recieved', 'low_availability',\n",
    "       'high_availability', 'complete', 'STL1_GDS0_DBLY', '2T_GDS0_SFC',\n",
    "       '2D_GDS0_SFC', 'STL2_GDS0_DBLY', 'STL3_GDS0_DBLY', 'SKT_GDS0_SFC',\n",
    "       'STL4_GDS0_DBLY', 'population']\n",
    "date_column = 'date'  # The column with dates\n",
    "lat_column = 'latitude'  # The column with latitude\n",
    "lon_column = 'longitude'  # The column with longitude\n",
    "\n",
    "# Create Dataset from CSV\n",
    "dataset = ERA5_With_Observations(csv_file=csv_file, \n",
    "                                label_columns=label_columns, \n",
    "                                date_column=date_column,\n",
    "                                lat_column=lat_column,\n",
    "                                lon_column=lon_column)\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first item\n",
    "item = dataset[0]\n",
    "\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1_variable_from_item(item, '2T_GDS0_SFC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1_variable_from_item(item, 'not_recieved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1_variable_from_item(item, 'population')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss-stack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
